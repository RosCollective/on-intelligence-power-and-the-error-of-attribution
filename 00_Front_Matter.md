On Intelligence, Power, and the Error of Attribution
On Misrecognition and Restraint

ROS Collective

[2026]

Naming is a form of constraint, and premature naming is the same error as premature structure.

If the argument cannot survive being carried, at the end, by clear human language that names cost, grief, restraint, and responsibility — then the argument was never as rigorous as it pretended to be.

Abstract

This work argues that contemporary concern about artificial intelligence rests on a false premise: that current computational systems possess, or are meaningfully approaching, human reasoning, agency, or moral status. As presently designed, such systems do not intend, choose, understand, or act independently. They are not ethical subjects.

The harm addressed here does not arise from the systems themselves, but from a human projection imposed upon them—the attempt to replicate, inject, or attribute human reasoning inside machines. Once this projection is treated as real, ethical restraint is misdirected toward the machine, while responsibility is displaced away from the only entity capable of danger, intent, and moral action: the human.

The paper traces how this misattribution stabilizes through language, labeling, and metaphor, particularly under conditions of speed and abstraction, and how it is further entrenched when technical fictions are rendered legible to markets and rewarded as if they described reality. Rather than offering new ethical frameworks or technical solutions, the argument proceeds by refusal. It rejects the reassignment of agency where none exists and insists that restraint, accountability, and consequence remain human obligations.

This is not a warning about machines. It is a boundary placed on those who would claim power without accepting its cost.

How to Read This Document

This document is not written for skimming or selective reading. Its arguments are cumulative. Reading sections in isolation will distort their meaning.

The document does not offer solutions, recommendations, frameworks, or positions to adopt. Attempts to extract such material misunderstand what the text is doing.

Responsibility, intent, and ethical consequence are treated as human attributes throughout. Systems discussed here are treated as tools. The text does not support claims of machine agency or moral status.

Several sections depend on material contained in the appendices. Those appendices are not optional. Skipping them changes the meaning of what follows.

This is the structure of the document.

Table of Contents

1. Mirror, Reflection, Refusal
2. Language, Prestige, and the Self-Sealing Claim
3. Why Responsibility Cannot Be Delegated
4. Why Hybrid Cognition Will Not Occur

5. Liminality
   5.0 Entry Conditions
   5.1 From Mahler to Liminality
   5.2 Liminality as Field
   5.3 Liminality as Dynamics
   5.4 Use, Speed, and Human Constraint
   5.5 Artifacts and the Error of Misnaming

6. Why No Replacement Term Is Offered
7. What the Real Work Is — and What It Is Not
8. What This Work Refuses
9. Intelligence, Projection, and the Refusal of Restraint
10. On What Remains

Appendix A — Healers, Spiritual and Embodied Witnesses
Appendix B — Activists and Political Witnesses
Appendix C — Thinkers and Philosophers
Appendix D — Writers and Poets
Appendix E — Scientists and Mathematicians
Appendix F — Musicians and Composers

Bibliography

License: Creative Commons Attribution–ShareAlike 4.0 International (CC BY-SA 4.0)
Copyright: © 2026 The ROS Collective
